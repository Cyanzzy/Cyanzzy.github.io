---
title: 企业开发进阶-2-Ngnix
date: 2023-07-22 15:59:43
tags: 
  - Nginx
categories: 
  - Technology
password: zzy   
message: 亲，能不能输入密码啊？
---

# Nginx

## Nginx 概述

Nginx 是**高性能的 HTTP 和反向代理的服务器**，处理高并发能力是十分强大的，能经受高负载的考验，有报告表明能支持高达 **50,000** 个并发连接数。  

##  正向代理 

在客户端配置代理服务器，通过代理服务器进行互联网访问

![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-01.png)

##  反向代理

 客户端不需要任何配置就可以访问，**只需要将请求发送到反向代理服务器**，由反向代理服务器去选择目标服务器获取数据后，**再返回给客户端**，**此时反向代理服务器和目标服务器对外就是一个服务器**，暴露的是代理服务器地址，隐藏了真实服务器IP 地址。  

![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-02.png)

## 负载均衡

增加服务器的数量，然后将请求分发到各个服务器上，将原先请求集中到单个服务器上的情况改为**将请求分发到多个服务器上**，**将负载分发到不同的服务器**

![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-03.png)

##  动静分离

为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度。降低原来单个服务器的压力。 

![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-04.png)

![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-05.png)

# Nginx常用命令和配置文件

## 常用命令

| 命令                       | 说明                       |
| -------------------------- | -------------------------- |
| `cd /usr/local/nginx/sbin` | 在Linux环境下进入nginx目录 |
| `./nginx -v`               | 查看nginx版本号            |
| `./nginx`                  | 启动nginx                  |
| `./nginx -s stop`          | 关闭nginx                  |
| `./nginx -s reload`        | 重新加载nginx              |

## 配置文件

> nginx配置文件位置

```bash
/usr/local/nginx/conf/nginx.conf    
```

> nginx配置文件组成

### 全局块

从配置文件开始到 events 块之间的内容，主要会**设置一些影响 nginx 服务器整体运行的配置指令**

> 主要包括

* 配置运行 Nginx 服务器的用户（组）
* 允许生成的 worker process 数，进程 PID 存放路径、日志存放路径和类型以 及配置文件的引入等。

如 `worker_processes  1;` 这是 Nginx 服务器并发处理服务的关键配置，`worker_processes` **值越大，可以支持的并发处理量也越多，但是会受到硬件、软件等设备的制约** 

### events块

events 块涉及的指令**主要影响 Nginx 服务器与用户的网络连接**

> 常用的设置包括

* 是否开启对多 work process 下的网络连接进行序列化
* 是否允许同时接收多个网络连接
* 选取哪种事件驱动模型来处理连接请求
* 每个 word process 可以同时支持的最大连接数等 	

### http块

http块是Nginx服务器配置中最频繁的部分， **代理、缓存和日志定义等绝大多数功能和第三方模块的配置**都在这里，http块也可以包括**http全局块、server块**

> http全局块

http 全局块配置的指令包括文件引入、MIME-TYPE 定义、日志自定义、连接超时时间、单链接请求数上限等 

> server块 

这块和虚拟主机有密切关系，虚拟主机从用户角度看，和一台独立的硬件主机是完全一样的，该技术的产生是为了节省互联网服务器硬件成本。 

*  每个 http 块可以包括多个 server 块，而**每个 server 块就相当于一个虚拟主机**
*  而每个 server 块也分为全局 server 块，以及可以同时包含多个 location 块。  

**全局 server 块** 

* 最常见的配置是本虚拟机主机的监听配置和本虚拟主机的名称或 IP 配置  

**location 块** 

* 一个 server 块可以配置多个 location 块。
* **主要作用是基于 Nginx 服务器接收到的请求字符串**（例如 server_name/uri-string），**对虚拟主机名称** （也可以是 IP 别名）**之外的字符串**（例如 前面的 /uri-string）进行匹配，**对特定的请求进行处理**
* 地址定向、数据缓 存和应答控制等功能，还有许多第三方模块的配置也在这里进行。  

> location 指令说明 

* **该指令用于匹配 URL。**

* 语法

  ```bash
  location [ = | ~ | ~* | ^~] uri {
  
  }
  ```

* `=` ：用于不含正则表达式的 uri 前，要求请求字符串与 uri 严格匹配，如果匹配 成功，就停止继续向下搜索并立即处理该请求

* ` ~` ：用于表示 uri 包含正则表达式，并且区分大小写

* `~*`：用于表示 uri 包含正则表达式，并且不区分大小写 

* `^~`：用于不含正则表达式的 uri 前，要求 Nginx 服务器找到标识 uri 和请求字 符串匹配度最高的 location 后，立即使用此 location 处理请求，而不再使用 location 块中的正则 uri 和请求字符串做匹配。

* **注意**：如果 uri 包含正则表达式，则必须要有 `~ `或者`~*` 标识  

# Nginx配置实例

## 配置反向代理

> 需求1：在浏览器地址栏输入地址www.123.com，跳转Linux系统tomcat主页面

> 准备工作

1. 在Linux系统中安装tomcat，使用默认端口8080

   * tomcat安装文件存入Linux系统，然后解压
   * 进入tomcat的bin目录，输入命令`./startup.sh`启动tomcat服务器

2. 对外开放访问的端口

   ```bash
   # 查看已经开放的端口号
   firewall-cmd --list-all
   # 开放端口
   firewall-cmd -add-port=8080/tcp --permanent
   # 重启防火墙
   firewall-cmd -reload
   ```

3. 在其他系统中通过浏览器访问tomcat服务器

> 访问过程分析

![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-06.png)

> 具体配置

第一步 在Windows系统的host文件进行域名和ip对应关系的配置

```text
192.168.17.129 www.123.com
```

第二步 在Nginx进行请求转发的配置（**反向代理的配置**）

![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-07.png)

![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-08.png)

> 需求2：使用Nginx反向代理，**根据访问的路径跳转到不同端口的服务中**
>
> * 监听端口9001
> * 访问http://127.0.0.1:9001/edu/ 跳转到127.0.0.1:8080
> * 访问http://127.0.0.1:9001/vod/ 跳转到127.0.0.1:8081

> 准备工作

* 准备两个tomcat服务器，一个8080端口，一个8081端口
* 创建文件夹和测试页面

> 具体配置

* 在Nginx配置文件中，完成反向代理配置

  ![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-09.png)

## 配置负载均衡

> 需求：浏览器地址栏输入地址http://192.168.17.129/edu/a.html，将请求均衡到8080和8081端口中

> 准备工作

* 准备两台tomcat服务器，8080和8081
* 在两台tomcat的webapps目录里创建edu文件夹，在edu文件夹中创建页面a.html用于测试

> Nginx配置文件进行负载均衡配置

![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-10.png)

## Nginx分配服务器策略

> **轮询**（默认）

每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。 

> weight，weight 代表权重默认为 1，权重越高被分配的客户端越多 

指定轮询几率，weight 和访问比率成正比，用于后端服务器性能不均的情况。  

![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-11.png)

> **ip_hash**

每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，**可以解决 session共享的问题**。 

![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-12.png)

> **fair**（第三方）

按后端服务器的响应时间来分配请求，响应时间短的优先分配。  

![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-13.png)

## 配置动静分离

简单来说就是**把动态跟静态请求分开**，不能理解成只是单纯的把动态页面和静态页面物理分离。**严格意义上说应该是动态请求跟静态请求分开，可以理解成使用 Nginx 处理静态页面，Tomcat 处理动态页面。**

动静分离从目前实现角度来讲大致分为两种， 

 一种是纯粹把静态文件独立成单独的域名，放在独立的服务器上； 另外一种方法就是动态跟静态文件混合在一起发布，通过 nginx 来分开。 

> 准备工作

在Linux环境中准备静态资源，用于访问

> 具体配置

找到 nginx 安装目录，打开/conf/nginx.conf 配置文件， 添加监听端口、访问名字， 重点是添加 location，最后检查 Nginx 配置是否正确即可，然后测试动静分离是否成功

![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-14.png)

# Nginx搭建高可用的集群

![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-15.png)

* Nginx服务器
* keepalived
* 虚拟ip

> 准备工作

* 需要两台服务器 192.168.17.129 和 192.168.17.131
* 在两台服务器安装 nginx
* 在两台服务器安装 keepalived  
  * ` yum install keepalived –y `
  * 安装之后，在 etc 里面生成目录 keepalived，有文件 keepalived.conf 

> 主从配置

修改`/etc/keepalived/keepalivec.conf` 配置文件 

```text
global_defs {
 notification_email {
 acassen@firewall.loc
 failover@firewall.loc
 sysadmin@firewall.loc
 }
 notification_email_from Alexandre.Cassen@firewall.loc
 smtp_server 192.168.17.129
 smtp_connect_timeout 30
 router_id LVS_DEVEL
}
vrrp_script chk_http_port {
 script "/usr/local/src/nginx_check.sh"
 interval 2 #（检测脚本执行的间隔）
 weight 2
}
vrrp_instance VI_1 {
 state BACKUP # 备份服务器上将 MASTER 改为 BACKUP
 interface ens33 //网卡
 virtual_router_id 51 # 主、备机的 virtual_router_id 必须相同
 priority 90 # 主、备机取不同的优先级，主机值较大，备份机值较小
 advert_int 1
authentication {
 auth_type PASS
 auth_pass 1111
 }
 virtual_ipaddress {
 192.168.17.50 // VRRP H 虚拟地址
 }
} 
```

在/usr/local/src 添加检测脚本 

```bash
#!/bin/bash
A=`ps -C nginx –no-header |wc -l`
if [ $A -eq 0 ];then
 /usr/local/nginx/sbin/nginx
 sleep 2
 if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then
 killall keepalived
 fi
fi
```

把两台服务器上 nginx 和 keepalived 启动 

* 启动 nginx：`./nginx`
* 启动 keepalived：`systemctl start keepalived.service `

> 最终测试 

* 在浏览器地址栏输入 虚拟 ip 地址 192.168.17.50  

  ![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-16.png)

  ![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-17.png)

* 把主服务器（192.168.17.129）nginx 和 keepalived 停止，再输入 192.168.17.50 

  

  ![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-18.png)

  ![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-19.png)

# Nginx原理

![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-20.png)

![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-21.png)

> worker如何工作

![](https://cyan-images.oss-cn-shanghai.aliyuncs.com/images/04-nginx-20230722-22.png)

> master-workers 的机制的优点

* 可以使用 `nginx –s reload` 热部署，利用 nginx 进行热部署操作
* 每个 woker 是独立的进程，如果有其中的一个 woker 出现问题，其他 woker 独立的， 继续进行争抢，实现请求过程，不会造成服务中断 

> 需要设置 worker 数量

* Nginx 同 Redis 类似都采用了 **io 多路复用机制**，每个 worker 都是一个独立的进程，但每个进程里只有一个主线程，通过异步非阻塞的方式来处理请求， 即使是千上万个请求也不在话下。

* 每个 worker 的线程可以把一个 cpu 的性能发挥到极致。**worker 数和服务器的 cpu 数相等是最为适宜的**。设少了会浪费 cpu，设多了会造成 cpu 频繁切换上下文带来的损耗。  

> 连接数 worker_connection 

* 连接数表示每个 worker 进程所能建立连接的最大值
* 所以，一个 nginx 能建立的最大连接数，应该是 worker_connections * worker_processes。
* 当然，这里说的是最大连接数
  * 对于 HTTP 请求本地资源来说 ， 能够支持的最大并发数量是 worker_connections * worker_processes
  * 如果是支持 http1.1 的浏览器每次访问要占两个连接，所以普通的静态访问最大并发数是： worker_connections * worker_processes /2
  * 而如果是 HTTP 作为反向代理来说，最大并发数量应该是 worker_connections * worker_processes/4。因为作为反向代理服务器，每个并发会建立与客户端的连接和与后端服 务的连接，会占用两个连接 

> 占用了 woker 的几个连接数？ 

2 或者 4 个 

> nginx 有一个 master，有四个 woker，每个 woker 支持最大的连接数 1024，支持的 最大并发数是多少？ 

* 普通的静态访问最大并发数是 ： worker_connections * worker_processes /2
* 如果是 HTTP 作 为反向代理来说，最大并发数量应该是 worker_connections * worker_processes/4。 